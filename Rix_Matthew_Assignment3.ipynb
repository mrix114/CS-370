{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (50000, 32, 32, 3)\n",
      "50000  train samples\n",
      "10000  test samples\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,168,362\n",
      "Trainable params: 2,168,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Augmenting training set images...\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "\n",
    "#CIFAR_10 set of 60k images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "\n",
    "#CONSTANTS\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 20\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop()\n",
    "\n",
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(X_train.shape[0], \" train samples\")\n",
    "print(X_test.shape[0], \" test samples\")\n",
    "\n",
    "\n",
    "#convert to categorical\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "#float and normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "#network\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', \n",
    "input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "#save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "NUM_TO_AUGMENT = 5\n",
    "\n",
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# augmenting\n",
    "print(\"Augmenting training set images...\")\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "rotation_range=40,\n",
    "width_shift_range=0.2,\n",
    "height_shift_range=0.2,\n",
    "zoom_range=0.2,\n",
    "horizontal_flip=True,\n",
    "fill_mode='nearest')\n",
    "\n",
    "xtas, ytas = [], []\n",
    "for i in range(X_train.shape[0]):\n",
    "    num_aug = 0\n",
    "x = X_train[i] # (3, 32, 32)\n",
    "x = x.reshape((1,) + x.shape) # (1, 3, 32, 32)\n",
    "for x_aug in datagen.flow(x, batch_size=1, \n",
    "save_to_dir='preview', save_prefix='cifar', save_format='jpeg'):\n",
    "    if num_aug >= NUM_TO_AUGMENT:\n",
    "        break\n",
    "xtas.append(x_aug[0])\n",
    "num_aug += 1\n",
    "\n",
    "\n",
    "#fit the datagen\n",
    "datagen.fit(X_train)\n",
    "\n",
    "#train\n",
    "history = model.fit_generator(\n",
    "    datagen.flow(\n",
    "        X_train, \n",
    "        Y_train, \n",
    "        batch_size=BATCH_SIZE),\n",
    "    samples_per_epoch=X_train.shape[0],\n",
    "    epochs=NB_EPOCH,\n",
    "    verbose=VERBOSE)\n",
    "\n",
    "score = model.evaluate(\n",
    "    X_test,\n",
    "    Y_test, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    verbose=VERBOSE)\n",
    "print(\"Test score: \", score[0])\n",
    "print(\"Test accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethical and Privacy concerns:\n",
    "This neural network has many ethical and practical concerns considering how inaccurate it is. Verifying the training data set for this algorithm is varied and unbiased as possible is very important as it could result in not only poor performance but also racial and sexist biases as well. Suppose that the training data was only pictures of only Eastern Asian male faces. The deep neural network would likely have difficulty recognizing Black people and Women. \n",
    "\n",
    "If used for something where the face was used to say open a automatic door then many would not be able to gain entrance into the space. Changing gears, suppose the training data set included pictures of real life people who did not consent to having their images used in a training algorithm. While it may not seem like a big deal you could have a situation in which an organization were to use the neural network to try and track large groups of people and report their findings to employers, government agencies, and various service providers. This could result in the person being denied employment, denied service, or inaccurately charged with criminal penalties. Law enforcements use of facial recognition technology (FRT) is concerning  because \"such usage is not disclosed, and people are not aware that they are under state survellance. The use of FRT has been marked by criticism of bias, discrimination, and lack of transparency\" (Sarabdeen). \n",
    "\n",
    "#### References:\n",
    "Sarabdeen, J. (Mar 2022). Protection of the rights of individuals when using facial recognitiontechnology. Retrieved from: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8927940"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
